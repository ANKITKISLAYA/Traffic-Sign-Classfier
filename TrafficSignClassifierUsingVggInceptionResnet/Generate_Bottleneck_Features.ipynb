{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ed437bb-b303-4c27-9320-b4c5896f8dff",
   "metadata": {},
   "source": [
    "### Bottleneck Feature generation for cifar10 and traffic dataset using Vgg, Resnet and Inception\n",
    "\n",
    "the code utilizes pre-trained CNN models to generate bottleneck features for a given dataset and saves them along with the labels. These bottleneck features can be used as input to train a different model or perform other tasks such as transfer learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5dc1318-c641-49b7-8300-0c269cb0f16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.8'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Tensorflow version\n",
    "import tensorflow as tf\n",
    "tf.version.VERSION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff276078-cbef-42f5-a4d6-6e1f4dfe37b7",
   "metadata": {},
   "source": [
    "#### Exploring cifar10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d6a15b1-dca6-4aed-942b-8e12526a3c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import cifar10\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "(X_train, y_train), (_, _) = cifar10.load_data()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a261c89-9c3a-490e-a212-f9250db05d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 32, 32, 3)\n",
      "(40000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db027ea-8d5b-4bae-ab9f-ef9412ce65ce",
   "metadata": {},
   "source": [
    "#### Checking GPU Access\n",
    "\n",
    "Here we have installed tensorflow-directml to access our AMD radeon graphics\n",
    "\n",
    "TensorFlow with DirectML enables training and inference of complex machine learning models on a wide range of DirectX 12-compatible hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24254e46-bf15-4057-b636-5efd749ad046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:DML:0', device_type='DML')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c75da92-3a93-4895-9b30-62706f477d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a53700-6d7e-45a3-8935-b81b74cd17db",
   "metadata": {},
   "source": [
    "#### Importing Necessary Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86460cb5-d693-4db6-b9c7-4c1adeaaf27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Input, AveragePooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "import pickle\n",
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd6496b-f320-4e03-a75f-b22221790d54",
   "metadata": {},
   "source": [
    "#### Defining the dataset to train, network to choose and set batch_size and height, width and channel of input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f58688ae-70d3-4b04-91e7-60389fe174f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make bottleneck features for either cifar10 or traffic dataset. \n",
    "dataset = 'cifar10'\n",
    "\n",
    "# The model to bottleneck, ex. 'vgg', 'inception', or 'resnet\n",
    "network = 'vgg'\n",
    "\n",
    "# The batch size for the generator\n",
    "batch_size = 128\n",
    "\n",
    "# Setting Height, Width and Channel of input \n",
    "h, w, ch = 224, 224, 3\n",
    "if network == 'inception':\n",
    "    h, w, ch = 299, 299, 3\n",
    "    from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "img_placeholder = tf.placeholder(\"uint8\", (None, 32, 32, 3))\n",
    "resize_op = tf.image.resize_images(img_placeholder, (h, w), method=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf15a1c-2be7-4fdb-b8a9-e7938779dfbe",
   "metadata": {},
   "source": [
    "#### Defining our generator Function to yield our batches of our Sample and batches of our labels\n",
    "\n",
    "generator takes a session, data, labels, and batch size as input and generates batches of preprocessed data and corresponding labels using TensorFlow operations. The generator is used to feed the data into the model during the prediction phase.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa60290d-251c-4fec-b649-7c8fac57a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen(session, data, labels, batch_size):\n",
    "    def _f():\n",
    "        start = 0\n",
    "        end = start + batch_size\n",
    "        n = data.shape[0]\n",
    " \n",
    "        while True:\n",
    "            X_batch = session.run(resize_op, {img_placeholder: data[start:end]})\n",
    "            X_batch = preprocess_input(X_batch)\n",
    "            y_batch = labels[start:end]\n",
    "            start += batch_size\n",
    "            end += batch_size\n",
    "            if start >= n:\n",
    "                start = 0\n",
    "                end = batch_size\n",
    "\n",
    "            print(start, end)\n",
    "            yield (X_batch, y_batch)\n",
    "\n",
    "    return _f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c52bfb-8c50-4c75-b321-2f995219cfaf",
   "metadata": {},
   "source": [
    "#### Creating model\n",
    "\n",
    "creates the selected CNN model (ResNet50, VGG16, or InceptionV3) and returns the model instance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0f67a18-b610-4dfc-9a46-239cef7783fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    input_tensor = Input(shape=(h, w, ch))\n",
    "    if network == 'vgg':\n",
    "        model = VGG16(input_tensor=input_tensor, include_top=False)\n",
    "        x = model.output\n",
    "        x = AveragePooling2D((7, 7))(x)\n",
    "        model = Model(model.input, x)\n",
    "    elif network == 'inception':\n",
    "        model = InceptionV3(input_tensor=input_tensor, include_top=False)\n",
    "        x = model.output\n",
    "        x = AveragePooling2D((8, 8), strides=(8, 8))(x)\n",
    "        model = Model(model.input, x)\n",
    "    else:\n",
    "        model = ResNet50(input_tensor=input_tensor, include_top=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcccd5b-f833-4c20-b730-ce3faa908b33",
   "metadata": {},
   "source": [
    "#### Loading the dataset selected either cifar10 or traffic signs and generating bottleneck features\n",
    "\n",
    "loading the dataset (either CIFAR10 or a traffic signs) and splits it into training and validation sets\n",
    "\n",
    "defining the output file names for saving the bottleneck features.\n",
    "\n",
    "creating a TensorFlow session and sets it as the default session.\n",
    "\n",
    "For the training dataset and validation dataset, the model.predict_generator method is called, passing the generator function and the number of samples in the training dataset. The resulting bottleneck features are saved along with the corresponding labels in a pickle file.\n",
    "\n",
    "Steps i have taken 313 for training and 79 for validation using Steps = len(X_train)/batch_size in order to cover whole dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7bf3512b-df2a-4454-a278-06b769f84be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing to (224, 224, 3)\n",
      "Saving to ...\n",
      "vgg_cifar10_bottleneck_features_train.p\n",
      "vgg_cifar10_bottleneck_features_validation.p\n",
      "Bottleneck training\n",
      "128 256\n",
      "256 384\n",
      "384 512\n",
      "512 640\n",
      "640 768\n",
      "768 896\n",
      "896 1024\n",
      "1024 1152\n",
      "1152 1280\n",
      "1280 1408\n",
      "1408 1536\n",
      "1536 1664\n",
      "1664 1792\n",
      "1792 1920\n",
      "1920 2048\n",
      "2048 2176\n",
      "2176 2304\n",
      "2304 2432\n",
      "2432 2560\n",
      "2560 2688\n",
      "2688 2816\n",
      "2816 2944\n",
      "2944 3072\n",
      "3072 3200\n",
      "3200 3328\n",
      "3328 3456\n",
      "3456 3584\n",
      "3584 3712\n",
      "3712 3840\n",
      "3840 3968\n",
      "3968 4096\n",
      "4096 4224\n",
      "4224 4352\n",
      "4352 4480\n",
      "4480 4608\n",
      "4608 4736\n",
      "4736 4864\n",
      "4864 4992\n",
      "4992 5120\n",
      "5120 5248\n",
      "5248 5376\n",
      "5376 5504\n",
      "5504 5632\n",
      "5632 5760\n",
      "5760 5888\n",
      "5888 6016\n",
      "6016 6144\n",
      "6144 6272\n",
      "6272 6400\n",
      "6400 6528\n",
      "6528 6656\n",
      "6656 6784\n",
      "6784 6912\n",
      "6912 7040\n",
      "7040 7168\n",
      "7168 7296\n",
      "7296 7424\n",
      "7424 7552\n",
      "7552 7680\n",
      "7680 7808\n",
      "7808 7936\n",
      "7936 8064\n",
      "8064 8192\n",
      "8192 8320\n",
      "8320 8448\n",
      "8448 8576\n",
      "8576 8704\n",
      "8704 8832\n",
      "8832 8960\n",
      "8960 9088\n",
      "9088 9216\n",
      "9216 9344\n",
      "9344 9472\n",
      "9472 9600\n",
      "9600 9728\n",
      "9728 9856\n",
      "9856 9984\n",
      "9984 10112\n",
      "10112 10240\n",
      "10240 10368\n",
      "10368 10496\n",
      "10496 10624\n",
      "10624 10752\n",
      "10752 10880\n",
      "10880 11008\n",
      "11008 11136\n",
      "11136 11264\n",
      "11264 11392\n",
      "11392 11520\n",
      "11520 11648\n",
      "11648 11776\n",
      "11776 11904\n",
      "11904 12032\n",
      "12032 12160\n",
      "12160 12288\n",
      "12288 12416\n",
      "12416 12544\n",
      "12544 12672\n",
      "12672 12800\n",
      "12800 12928\n",
      "12928 13056\n",
      "13056 13184\n",
      "13184 13312\n",
      "13312 13440\n",
      "13440 13568\n",
      "13568 13696\n",
      "13696 13824\n",
      "13824 13952\n",
      "13952 14080\n",
      "14080 14208\n",
      "14208 14336\n",
      "14336 14464\n",
      "14464 14592\n",
      "14592 14720\n",
      "14720 14848\n",
      "14848 14976\n",
      "14976 15104\n",
      "15104 15232\n",
      "15232 15360\n",
      "15360 15488\n",
      "15488 15616\n",
      "15616 15744\n",
      "15744 15872\n",
      "15872 16000\n",
      "16000 16128\n",
      "16128 16256\n",
      "16256 16384\n",
      "16384 16512\n",
      "16512 16640\n",
      "16640 16768\n",
      "16768 16896\n",
      "16896 17024\n",
      "17024 17152\n",
      "17152 17280\n",
      "17280 17408\n",
      "17408 17536\n",
      "17536 17664\n",
      "17664 17792\n",
      "17792 17920\n",
      "17920 18048\n",
      "18048 18176\n",
      "18176 18304\n",
      "18304 18432\n",
      "18432 18560\n",
      "18560 18688\n",
      "18688 18816\n",
      "18816 18944\n",
      "18944 19072\n",
      "19072 19200\n",
      "19200 19328\n",
      "19328 19456\n",
      "19456 19584\n",
      "19584 19712\n",
      "19712 19840\n",
      "19840 19968\n",
      "19968 20096\n",
      "20096 20224\n",
      "20224 20352\n",
      "20352 20480\n",
      "20480 20608\n",
      "20608 20736\n",
      "20736 20864\n",
      "20864 20992\n",
      "20992 21120\n",
      "21120 21248\n",
      "21248 21376\n",
      "21376 21504\n",
      "21504 21632\n",
      "21632 21760\n",
      "21760 21888\n",
      "21888 22016\n",
      "22016 22144\n",
      "22144 22272\n",
      "22272 22400\n",
      "22400 22528\n",
      "22528 22656\n",
      "22656 22784\n",
      "22784 22912\n",
      "22912 23040\n",
      "23040 23168\n",
      "23168 23296\n",
      "23296 23424\n",
      "23424 23552\n",
      "23552 23680\n",
      "23680 23808\n",
      "23808 23936\n",
      "23936 24064\n",
      "24064 24192\n",
      "24192 24320\n",
      "24320 24448\n",
      "24448 24576\n",
      "24576 24704\n",
      "24704 24832\n",
      "24832 24960\n",
      "24960 25088\n",
      "25088 25216\n",
      "25216 25344\n",
      "25344 25472\n",
      "25472 25600\n",
      "25600 25728\n",
      "25728 25856\n",
      "25856 25984\n",
      "25984 26112\n",
      "26112 26240\n",
      "26240 26368\n",
      "26368 26496\n",
      "26496 26624\n",
      "26624 26752\n",
      "26752 26880\n",
      "26880 27008\n",
      "27008 27136\n",
      "27136 27264\n",
      "27264 27392\n",
      "27392 27520\n",
      "27520 27648\n",
      "27648 27776\n",
      "27776 27904\n",
      "27904 28032\n",
      "28032 28160\n",
      "28160 28288\n",
      "28288 28416\n",
      "28416 28544\n",
      "28544 28672\n",
      "28672 28800\n",
      "28800 28928\n",
      "28928 29056\n",
      "29056 29184\n",
      "29184 29312\n",
      "29312 29440\n",
      "29440 29568\n",
      "29568 29696\n",
      "29696 29824\n",
      "29824 29952\n",
      "29952 30080\n",
      "30080 30208\n",
      "30208 30336\n",
      "30336 30464\n",
      "30464 30592\n",
      "30592 30720\n",
      "30720 30848\n",
      "30848 30976\n",
      "30976 31104\n",
      "31104 31232\n",
      "31232 31360\n",
      "31360 31488\n",
      "31488 31616\n",
      "31616 31744\n",
      "31744 31872\n",
      "31872 32000\n",
      "32000 32128\n",
      "32128 32256\n",
      "32256 32384\n",
      "32384 32512\n",
      "32512 32640\n",
      "32640 32768\n",
      "32768 32896\n",
      "32896 33024\n",
      "33024 33152\n",
      "33152 33280\n",
      "33280 33408\n",
      "33408 33536\n",
      "33536 33664\n",
      "33664 33792\n",
      "33792 33920\n",
      "33920 34048\n",
      "34048 34176\n",
      "34176 34304\n",
      "34304 34432\n",
      "34432 34560\n",
      "34560 34688\n",
      "34688 34816\n",
      "34816 34944\n",
      "34944 35072\n",
      "35072 35200\n",
      "35200 35328\n",
      "35328 35456\n",
      "35456 35584\n",
      "35584 35712\n",
      "35712 35840\n",
      "35840 35968\n",
      "35968 36096\n",
      "36096 36224\n",
      "36224 36352\n",
      "36352 36480\n",
      "36480 36608\n",
      "36608 36736\n",
      "36736 36864\n",
      "36864 36992\n",
      "36992 37120\n",
      "37120 37248\n",
      "37248 37376\n",
      "37376 37504\n",
      "37504 37632\n",
      "37632 37760\n",
      "37760 37888\n",
      "37888 38016\n",
      "38016 38144\n",
      "38144 38272\n",
      "38272 38400\n",
      "38400 38528\n",
      "38528 38656\n",
      "38656 38784\n",
      "38784 38912\n",
      "38912 39040\n",
      "39040 39168\n",
      "39168 39296\n",
      "39296 39424\n",
      "39424 39552\n",
      "39552 39680\n",
      "39680 39808\n",
      "39808 39936\n",
      "39936 40064\n",
      "0 128\n",
      "128 256\n",
      "256 384\n",
      "384 512\n",
      "512 640\n",
      "640 768\n",
      "768 896\n",
      "896 1024\n",
      "1024 1152\n",
      "1152 1280\n",
      "1280 1408\n",
      "1408 1536\n",
      "Bottleneck validation\n",
      "128 256\n",
      "256 384\n",
      "384 512\n",
      "512 640\n",
      "640 768\n",
      "768 896\n",
      "896 1024\n",
      "1024 1152\n",
      "1152 1280\n",
      "1280 1408\n",
      "1408 1536\n",
      "1536 1664\n",
      "1664 1792\n",
      "1792 1920\n",
      "1920 2048\n",
      "2048 2176\n",
      "2176 2304\n",
      "2304 2432\n",
      "2432 2560\n",
      "2560 2688\n",
      "2688 2816\n",
      "2816 2944\n",
      "2944 3072\n",
      "3072 3200\n",
      "3200 3328\n",
      "3328 3456\n",
      "3456 3584\n",
      "3584 3712\n",
      "3712 3840\n",
      "3840 3968\n",
      "3968 4096\n",
      "4096 4224\n",
      "4224 4352\n",
      "4352 4480\n",
      "4480 4608\n",
      "4608 4736\n",
      "4736 4864\n",
      "4864 4992\n",
      "4992 5120\n",
      "5120 5248\n",
      "5248 5376\n",
      "5376 5504\n",
      "5504 5632\n",
      "5632 5760\n",
      "5760 5888\n",
      "5888 6016\n",
      "6016 6144\n",
      "6144 6272\n",
      "6272 6400\n",
      "6400 6528\n",
      "6528 6656\n",
      "6656 6784\n",
      "6784 6912\n",
      "6912 7040\n",
      "7040 7168\n",
      "7168 7296\n",
      "7296 7424\n",
      "7424 7552\n",
      "7552 7680\n",
      "7680 7808\n",
      "7808 7936\n",
      "7936 8064\n",
      "8064 8192\n",
      "8192 8320\n",
      "8320 8448\n",
      "8448 8576\n",
      "8576 8704\n",
      "8704 8832\n",
      "8832 8960\n",
      "8960 9088\n",
      "9088 9216\n",
      "9216 9344\n",
      "9344 9472\n",
      "9472 9600\n",
      "9600 9728\n",
      "9728 9856\n",
      "9856 9984\n",
      "9984 10112\n",
      "0 128\n",
      "128 256\n",
      "256 384\n",
      "384 512\n",
      "512 640\n",
      "640 768\n",
      "768 896\n",
      "896 1024\n",
      "1024 1152\n",
      "1152 1280\n",
      "1280 1408\n",
      "1408 1536\n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "if dataset == 'cifar10':\n",
    "    (X_train, y_train), (_, _) = cifar10.load_data()\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "else:\n",
    "    with open('data/train.p', mode='rb') as f:\n",
    "        train = pickle.load(f)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train['features'], train['labels'], test_size=0.33, random_state=0)\n",
    "\n",
    "train_output_file = \"{}_{}_{}.p\".format(network, dataset, 'bottleneck_features_train')\n",
    "validation_output_file = \"{}_{}_{}.p\".format(network, dataset, 'bottleneck_features_validation')\n",
    "\n",
    "print(\"Resizing to\", (w, h, ch))\n",
    "print(\"Saving to ...\")\n",
    "print(train_output_file)\n",
    "print(validation_output_file)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    K.set_session(sess)\n",
    "    K.set_learning_phase(1)\n",
    "\n",
    "    model = create_model()\n",
    "\n",
    "    # The model.predict_generator function returns an array of predicted probabilities,\n",
    "    # where each row corresponds to \n",
    "    # a sample in the test set, and each column represents the probability \n",
    "    # of the sample belonging to a specific class.\n",
    "    print('Bottleneck training')\n",
    "    train_gen = gen(sess, X_train, y_train, batch_size)\n",
    "    # predict_generator Generates predictions for the input samples from a data generator\n",
    "    bottleneck_features_train = model.predict_generator(train_gen(), steps=313)\n",
    "    data = {'features': bottleneck_features_train, 'labels': y_train}\n",
    "    pickle.dump(data, open(train_output_file, 'wb'))\n",
    "\n",
    "    print('Bottleneck validation')\n",
    "    val_gen = gen(sess, X_val, y_val, batch_size)\n",
    "    bottleneck_features_validation = model.predict_generator(val_gen(), steps=79)\n",
    "    data = {'features': bottleneck_features_validation, 'labels': y_val}\n",
    "    pickle.dump(data, open(validation_output_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e79ef5-553c-4517-8d3f-f9fa2ce61eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29ce24da-719d-43e7-9c76-1d559e1c1e21",
   "metadata": {},
   "source": [
    "#### Reading the pickle file generated and exploring the features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69cb5b86-4bcb-4c85-b199-73c25e5e066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import collections, numpy as np\n",
    "\n",
    "training_file = \"vgg_cifar10_bottleneck_features_train.p\"\n",
    "validation_file = \"vgg_cifar10_bottleneck_features_validation.p\"\n",
    "\n",
    "with open(training_file, 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open(validation_file, 'rb') as f:\n",
    "    validation_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fcd743fb-e91c-4641-8e7b-dbb7be384f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bottleneck features shape :- (40000, 1, 1, 512)\n",
      "Training Bottleneck labels shape :- (40000, 1)\n",
      "Validation Bottleneck features shape :- (10000, 1, 1, 512)\n",
      "Validation Bottleneck labels shape :- (10000, 1)\n",
      "Unique Classes :- [0 1 2 3 4 5 6 7 8 9]\n",
      "Number of Examples in each Class :- Counter({6: 4047, 4: 4033, 1: 4014, 8: 4011, 7: 4001, 0: 3996, 5: 3984, 2: 3984, 3: 3970, 9: 3960})\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Bottleneck features shape :-\",train_data['features'].shape)\n",
    "print(\"Training Bottleneck labels shape :-\",train_data['labels'].shape)\n",
    "print(\"Validation Bottleneck features shape :-\",validation_data['features'].shape)\n",
    "print(\"Validation Bottleneck labels shape :-\",validation_data['labels'].shape)\n",
    "print(\"Unique Classes :-\", np.unique(train_data['labels']))\n",
    "labels = train_data['labels'].reshape(train_data['labels'].shape[0])\n",
    "counter = collections.Counter(labels)\n",
    "print(\"Number of Examples in each Class :-\", counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ffbb43-36a8-45a1-85ae-fae24490bd65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
